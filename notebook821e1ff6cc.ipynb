{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Mental Health in Tech**\n\nThe ongoing 2016 poll, which has received over 1400 responses so far, attempts to measure attitudes towards mental health in the tech industry and look into the widespread presence of mental health illnesses among tech professionals.","metadata":{"execution":{"iopub.status.busy":"2023-10-05T16:21:02.865267Z","iopub.execute_input":"2023-10-05T16:21:02.865688Z","iopub.status.idle":"2023-10-05T16:21:02.874733Z","shell.execute_reply.started":"2023-10-05T16:21:02.865661Z","shell.execute_reply":"2023-10-05T16:21:02.872764Z"}}},{"cell_type":"markdown","source":"# **1. Business Understanding**\n### **Identify the business task and translate it into an Unsupervised Machine Learning Task:**\nThe main goal of this project is to assist the HR division in proactively addressing mental health issues among the company's technology-focused personnel. I hope to find possible leverage points for a preventative programme to reduce mental health problems among the workforce of the organisation\n### **Consider key stakeholders:**\nKey stakeholders include: \n* HR Department: As the main stakeholder, the HR department is in charge of putting programmes in place to enhance employee mental health.\n* Company management at the company is interested in promoting a healthier and more effective working environment.\n* Employees: It is crucial to consider each employee's physical and emotional wellbeing.\n### **Key Questions and Goals:**\n* Mental Health Clusters: Can we group employees according to their responses to surveys on their mental health and well-being?\n* Patterns: Are there any patterns in the data that could be used to identify potential points of leverage for the pre-emptive program?\n* HR is recommended to: What useful conclusions and suggestions may be drawn from the cluster analysis to enhance workplace mental health programmes and support systems?","metadata":{}},{"cell_type":"markdown","source":"# **2. Data Understanding**\n### Key tasks:\n* Data Collection: Download data and store it appropriately.\n* Identify how it’s organized.\n* Preliminary data exploration\n\n### Data Collection\nData has been downloaded from OSMI Mental Health in Tech Survey 2016 (https://www.kaggle.com/datasets/osmi/mental-health-in-tech-2016). Local copies have been stored here on Kaggle.\n\n### Identify how it's organized.\nData is in comma separated values (.CSV) format.\n\n### Preliminary data exploration","metadata":{"execution":{"iopub.status.busy":"2023-10-05T16:22:29.914135Z","iopub.execute_input":"2023-10-05T16:22:29.914599Z","iopub.status.idle":"2023-10-05T16:22:29.923057Z","shell.execute_reply.started":"2023-10-05T16:22:29.914567Z","shell.execute_reply":"2023-10-05T16:22:29.921755Z"}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import silhouette_score\n\nimport geopandas as gpd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv('/kaggle/input/mental-health-in-tech-2016/mental-heath-in-tech-2016_20161114.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-01T11:35:35.861636Z","iopub.execute_input":"2023-11-01T11:35:35.862056Z","iopub.status.idle":"2023-11-01T11:35:38.260329Z","shell.execute_reply.started":"2023-11-01T11:35:35.862018Z","shell.execute_reply":"2023-11-01T11:35:38.259403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring the data","metadata":{}},{"cell_type":"code","source":"data.head","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:38.262330Z","iopub.execute_input":"2023-11-01T11:35:38.262977Z","iopub.status.idle":"2023-11-01T11:35:38.294431Z","shell.execute_reply.started":"2023-11-01T11:35:38.262936Z","shell.execute_reply":"2023-11-01T11:35:38.293370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:38.295864Z","iopub.execute_input":"2023-11-01T11:35:38.296267Z","iopub.status.idle":"2023-11-01T11:35:38.315976Z","shell.execute_reply.started":"2023-11-01T11:35:38.296229Z","shell.execute_reply":"2023-11-01T11:35:38.315029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of rows: {data.shape[0]}\\nNumber of columns: {data.shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:38.318181Z","iopub.execute_input":"2023-11-01T11:35:38.318777Z","iopub.status.idle":"2023-11-01T11:35:38.325985Z","shell.execute_reply.started":"2023-11-01T11:35:38.318747Z","shell.execute_reply":"2023-11-01T11:35:38.325205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the number of missing values values as percentage\ntotal_rows = len(data)\nmissing_values = data.isnull().sum()\nnan_col = ((missing_values/total_rows)*100).round().astype(int)\nnan_col = nan_col.sort_values(ascending=False)\nnan_col = nan_col.apply(lambda x: f\"{x}%\")\nnan_col.head(15)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:38.327221Z","iopub.execute_input":"2023-11-01T11:35:38.327787Z","iopub.status.idle":"2023-11-01T11:35:38.347736Z","shell.execute_reply.started":"2023-11-01T11:35:38.327759Z","shell.execute_reply":"2023-11-01T11:35:38.346707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_col = (missing_values / total_rows) * 100\n\n# Sort the columns by the percentage of missing values in descending order\nnan_col = nan_col.sort_values(ascending=False)\n\n# Create a bar chart with Seaborn\nplt.figure(figsize=(12, 6))\nsns.barplot(x=nan_col.index, y=nan_col, palette='viridis')\nplt.title('Percentage of Missing Values in Features')\nplt.xlabel('Columns')\nplt.ylabel('Percentage Missing')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:38.348754Z","iopub.execute_input":"2023-11-01T11:35:38.349729Z","iopub.status.idle":"2023-11-01T11:35:39.699119Z","shell.execute_reply.started":"2023-11-01T11:35:38.349689Z","shell.execute_reply":"2023-11-01T11:35:39.697802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before cleaning the data and pre-preprocessing it. I noticed the the names of the the features are very long.\n# I am going to rename them to avoid mistyping the column names\n\ndf = data.copy()\n\n# Define new column names for all columns\nnew_column_names = {\n    'Are you self-employed?': 'Self_Employed',\n    'How many employees does your company or organization have?': 'Company_Size',\n    'Is your employer primarily a tech company/organization?': 'Tech_Company',\n    'Is your primary role within your company related to tech/IT?': 'Tech_Role',\n    'Does your employer provide mental health benefits as part of healthcare coverage?': 'MH_Benefits',\n    'Do you know the options for mental health care available under your employer-provided coverage?': 'MH_Coverage_Options',\n    'Has your employer ever formally discussed mental health (for example, as part of a wellness campaign or other official communication)?': 'Formal_MH_Discussion',\n    'Does your employer offer resources to learn more about mental health concerns and options for seeking help?': 'MH_Resources',\n    'Is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources provided by your employer?': 'Anonymity_Protection',\n    'If a mental health issue prompted you to request a medical leave from work, asking for that leave would be:': 'Mental_Health_Medical_Leave',\n    'Do you think that discussing a mental health disorder with your employer would have negative consequences?': 'Discussing_MH_Neg_Consequences',\n    'Do you think that discussing a physical health issue with your employer would have negative consequences?': 'Discussing_PH_Neg_Consequences',\n    'Would you feel comfortable discussing a mental health disorder with your coworkers?': 'Comfort_Discussing_MH_Coworkers',\n    'Would you feel comfortable discussing a mental health disorder with your direct supervisor(s)?': 'Comfort_Discussing_MH_Supervisors',\n    'Do you feel that your employer takes mental health as seriously as physical health?': 'Employer_Takes_MH_Seriously_as_PH',\n    'Have you heard of or observed negative consequences for co-workers who have been open about mental health issues in your workplace?': 'Observed_Neg_Consequences_Coworkers_MH',\n    'Do you have medical coverage (private insurance or state-provided) which includes treatment of mental health issues?': 'Medical_Coverage_MH',\n    'Do you know local or online resources to seek help for a mental health disorder?': 'Know_Resources_Seek_Help_MH',\n    'If you have been diagnosed or treated for a mental health disorder, do you ever reveal this to clients or business contacts?': 'Reveal_MH_Clients',\n    'If you have revealed a mental health issue to a client or business contact, do you believe this has impacted you negatively?': 'Impact_Revealing_MH_Clients',\n    'If you have been diagnosed or treated for a mental health disorder, do you ever reveal this to coworkers or employees?': 'Reveal_MH_Coworkers',\n    'If you have revealed a mental health issue to a coworker or employee, do you believe this has impacted you negatively?': 'Impact_Revealing_MH_Coworkers',\n    'Do you believe your productivity is ever affected by a mental health issue?': 'Productivity_Affected_MH',\n    'If yes, what percentage of your work time (time performing primary or secondary job functions) is affected by a mental health issue?': 'Percentage_Work_Time_Affected_MH',\n    'Do you have previous employers?': 'Previous_Employers',\n    'Have your previous employers provided mental health benefits?': 'Previous_Employers_MH_Benefits',\n    'Were you aware of the options for mental health care provided by your previous employers?': 'Previous_Employers_MH_Care_Options',\n    'Did your previous employers ever formally discuss mental health (as part of a wellness campaign or other official communication)?': 'Previous_Employers_Formal_MH_Discussion',\n    'Did your previous employers provide resources to learn more about mental health issues and how to seek help?': 'Previous_Employers_Mental_Health_Resources',\n    'Was your anonymity protected if you chose to take advantage of mental health or substance abuse treatment resources with previous employers?': 'Previous_Employers_Anonymity_Protection',\n    'Do you think that discussing a mental health disorder with previous employers would have negative consequences?': 'Discussing_MH_Previous_Neg_Consequences',\n    'Do you think that discussing a physical health issue with previous employers would have negative consequences?': 'Discussing_PH_Previous_Neg_Consequences',\n    'Would you have been willing to discuss a mental health issue with your previous co-workers?': 'Discuss_MH_Previous_Coworkers',\n    'Would you have been willing to discuss a mental health issue with your direct supervisor(s)?': 'Discuss_MH_Previous_Supervisors',\n    'Did you feel that your previous employers took mental health as seriously as physical health?': 'Previous_Employers_Take_MH_Seriously',\n    'Did you hear of or observe negative consequences for co-workers with mental health issues in your previous workplaces?': 'Observed_Neg_Consequences_Previous_Coworkers_MH',\n    'Would you be willing to bring up a physical health issue with a potential employer in an interview?': 'Willing_Bring_Up_PH_Interview',\n    'Why or why not?': 'Reasons_Bring_Up_PH',\n    'Would you bring up a mental health issue with a potential employer in an interview?': 'Willing_Bring_Up_MH_Interview',\n    'Why or why not?.1': 'Reasons_Bring_Up_MH',\n    'Do you feel that being identified as a person with a mental health issue would hurt your career?': 'MH_Identifier_Neg_Career_Impact',\n    'Do you think that team members/co-workers would view you more negatively if they knew you suffered from a mental health issue?': 'Team_View_Negatively_Know_MH_Issue',\n    'How willing would you be to share with friends and family that you have a mental illness?': 'Willing_Share_MH_Friends_Family',\n    'Have you observed or experienced an unsupportive or badly handled response to a mental health issue in your current or previous workplace?': 'Observed_Unsupportive_Response_MH_Workplace',\n    'Have your observations of how another individual who discussed a mental health disorder made you less likely to reveal a mental health issue yourself in your current workplace?': 'Observations_Affect_Likelihood_Reveal_MH_Workplace',\n    'Do you have a family history of mental illness?': 'Family_History_MH',\n    'Have you had a mental health disorder in the past?': 'Past_MH_Disorder',\n    'Do you currently have a mental health disorder?': 'Current_MH_Disorder',\n    'If yes, what condition(s) have you been diagnosed with?': 'Diagnosed_Conditions',\n    'If maybe, what condition(s) do you believe you have?': 'Suspected_Conditions',\n    'Have you been diagnosed with a mental health condition by a medical professional?': 'Diagnosed_By_Medical_Professional_with_MH',\n    'If so, what condition(s) were you diagnosed with?': 'Diagnosed_Conditions_Professional',\n    'Have you ever sought treatment for a mental health issue from a mental health professional?': 'Sought_Treatment_MH_Professional',\n    'If you have a mental health issue, do you feel that it interferes with your work when being treated effectively?': 'MH_Interference_With_Work_Treated_Effectively',\n    'If you have a mental health issue, do you feel that it interferes with your work when NOT being treated effectively?': 'MH_Interference_With_Work_Not_Treated_Effectively',\n    'What is your age?': 'Age',\n    'What is your gender?': 'Gender',\n    'What country do you live in?': 'Country_Live',\n    'What US state or territory do you live in?': 'US_State_Live',\n    'What country do you work in?': 'Country_Work',\n    'What US state or territory do you work in?': 'US_State_Work',\n    'Which of the following best describes your work position?': 'Work_Position',\n    'Do you work remotely?': 'Work_Remotely'\n}\n\n# Rename the columns\ndf.rename(columns=new_column_names, inplace=True)\n\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.701056Z","iopub.execute_input":"2023-11-01T11:35:39.701578Z","iopub.status.idle":"2023-11-01T11:35:39.726240Z","shell.execute_reply.started":"2023-11-01T11:35:39.701528Z","shell.execute_reply":"2023-11-01T11:35:39.724959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3. Data Preparation**\n### Key tasks:\n* Handling Missing Values \n* Data Transformation.\n* Correcting wrong data format.","metadata":{}},{"cell_type":"markdown","source":"## Handling missing values","metadata":{}},{"cell_type":"code","source":"threshold = 0.4\n\n# Calculate the percentage of missing values for each column\nmissing_percentage = (df.isnull().sum() / len(df))\n\n# Get the list of columns with missing values exceeding the threshold\ncolumns_to_drop = missing_percentage[missing_percentage >= threshold].index.tolist()\n\n# Drop the identified columns from the DataFrame\ndf = df.drop(columns=columns_to_drop)\n\ncategorical_col = df.select_dtypes(include=['object']).columns\nnum_col = df.select_dtypes(include=['float64','int64']).columns\n\nnum_imputer = SimpleImputer(strategy = 'mean')\ncategorical_imputer = SimpleImputer(strategy='most_frequent')\n\ndf[categorical_col] = categorical_imputer.fit_transform(df[categorical_col])\ndf[num_col] = num_imputer.fit_transform(df[num_col])","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.727750Z","iopub.execute_input":"2023-11-01T11:35:39.728432Z","iopub.status.idle":"2023-11-01T11:35:39.779532Z","shell.execute_reply.started":"2023-11-01T11:35:39.728400Z","shell.execute_reply":"2023-11-01T11:35:39.778376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_values = {}  # Create a dictionary to store unique values\n\nfor column in df.columns:\n    unique_values[column] = df[column].unique()\n\n# Print unique values for each column\nfor column, values in unique_values.items():\n    print(f'Column: {column}')\n    print(f'Unique Values: {values}')\n    print('-------------------------------------')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.780896Z","iopub.execute_input":"2023-11-01T11:35:39.781210Z","iopub.status.idle":"2023-11-01T11:35:39.806236Z","shell.execute_reply.started":"2023-11-01T11:35:39.781185Z","shell.execute_reply":"2023-11-01T11:35:39.805097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Incorrect data values","metadata":{}},{"cell_type":"code","source":"def clean(df, column_name):\n\n    def calculate_average(value):\n        if isinstance(value, str) and '-' in value:\n            min_value, max_value = map(int, value.split('-'))\n            return (min_value + max_value) / 2\n        else:\n            return value\n    \n    df[column_name] = df[column_name].apply(calculate_average)\n\n    return df\n\ndf = clean(df,'Company_Size')\n\n# Replace \"More than 1000\" with a suitable upper limit: 1400\ndf['Company_Size'] = df['Company_Size'].replace(\"More than 1000\", 1400)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.811099Z","iopub.execute_input":"2023-11-01T11:35:39.811601Z","iopub.status.idle":"2023-11-01T11:35:39.822219Z","shell.execute_reply.started":"2023-11-01T11:35:39.811553Z","shell.execute_reply":"2023-11-01T11:35:39.820806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the tolerance level for comparing values\ntolerance = 1e-6  # Adjust the tolerance level as needed\n\n# Replace values in the 'Tech_Company' column with 1 using tolerance\ndf['Tech_Company'] = np.where(np.isclose(df['Tech_Company'], 0.770506108202443, atol=tolerance) | np.isclose(df['Tech_Company'], 0.770506, atol=tolerance), 1, df['Tech_Company'])","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.823924Z","iopub.execute_input":"2023-11-01T11:35:39.824787Z","iopub.status.idle":"2023-11-01T11:35:39.837011Z","shell.execute_reply.started":"2023-11-01T11:35:39.824737Z","shell.execute_reply":"2023-11-01T11:35:39.835805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the gender mapping dictionary\ngender_mapping = {\n    'Male': 'Male',\n    'male': 'Male',\n    'Male ': 'Male',\n    'Female': 'Female',\n    'M': 'Male',\n    'female': 'Female',\n    'm': 'Male',\n    \"I identify as female.\": 'Female',\n    'female ': 'Female',\n    'Bigender': 'Bigender',\n    'non-binary': 'Non-binary',\n    'Female assigned at birth ': 'Female',\n    'F': 'Female',\n    'Woman': 'Female',\n    'man': 'Male',\n    'fm': 'Female',\n    'f': 'Female',\n    'Cis female ': 'Female',\n    'Transitioned, M2F': 'Transgender Female',\n    'Genderfluid (born female)': 'Genderfluid',\n    'Other/Transfeminine': 'Other',\n    'Female or Multi-Gender Femme': 'Female',\n    'Female ': 'Female',\n    'woman': 'Female',\n    'female/woman': 'Female',\n    'Cis male': 'Male',\n    'Male.': 'Male',\n    'Androgynous': 'Other',\n    'male 9:1 female, roughly': 'Male',\n    'Male (cis)': 'Male',\n    'Other': 'Other',\n    'nb masculine': 'Male',\n    'Cisgender Female': 'Female',\n    'Man': 'Male',\n    'Sex is male': 'Male',\n    'none of your business': 'Male',\n    'genderqueer': 'Genderqueer',\n    'cis male': 'Male',\n    'Human': 'Male',\n    'Genderfluid': 'Genderfluid',\n    'Enby': 'Non-binary',\n    'Malr': 'Male',\n    'genderqueer woman': 'Genderqueer',\n    'mtf': 'Transgender',\n    'Queer': 'Other',\n    'Agender': 'Agender',\n    'Dude': 'Male',\n    'Fluid': 'Other',\n    \"I'm a man why didn't you make this a drop down question. You should of asked sex? And I would of answered yes please. Seriously how much text can this take? \": 'Male',\n    'mail': 'Male',\n    'M|': 'Male',\n    'Male/genderqueer': 'Other',\n    'fem': 'Female',\n    'Nonbinary': 'Non-binary',\n    'male ': 'Male',\n    'human': 'Male',\n    'Female (props for making this a freeform field, though)': 'Female',\n    ' Female': 'Female',\n    'Unicorn': 'Male',\n    'Cis Male': 'Male',\n    'Male (trans, FtM)': 'Transgender Male',\n    'Cis-woman': 'Female',\n    'Genderqueer': 'Genderqueer',\n    'cisdude': 'Male',\n    'Genderflux demi-girl': 'Genderqueer',\n    'female-bodied; no feelings about gender': 'Female',\n    'cis man': 'Male',\n    'AFAB': 'Female',\n    'Transgender woman': 'Transgender Female',\n    'MALE': 'Male'\n}\n\n# Replace values in the 'gender' column using the mapping\ndf['Gender'] = df['Gender'].map(gender_mapping)\n\nmost_frequent_gender = df['Gender'].mode()[0]\ndf['Gender'].fillna(most_frequent_gender, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.838624Z","iopub.execute_input":"2023-11-01T11:35:39.839227Z","iopub.status.idle":"2023-11-01T11:35:39.854592Z","shell.execute_reply.started":"2023-11-01T11:35:39.839193Z","shell.execute_reply":"2023-11-01T11:35:39.853291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the mean age, excluding values less than 18 and greater than 75\nmean_age = np.mean(df[(df['Age'] >= 18) & (df['Age'] <= 75)]['Age'])\n\n# Replace values less than 18 and greater than 75 with the calculated mean age\ndf['Age'] = np.where((df['Age'] < 18) | (df['Age'] > 75), mean_age, df['Age'])\ndf['Age'] = df['Age'].round().astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.856323Z","iopub.execute_input":"2023-11-01T11:35:39.856747Z","iopub.status.idle":"2023-11-01T11:35:39.876709Z","shell.execute_reply.started":"2023-11-01T11:35:39.856705Z","shell.execute_reply":"2023-11-01T11:35:39.875624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.878124Z","iopub.execute_input":"2023-11-01T11:35:39.879183Z","iopub.status.idle":"2023-11-01T11:35:39.888763Z","shell.execute_reply.started":"2023-11-01T11:35:39.879120Z","shell.execute_reply":"2023-11-01T11:35:39.887559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Certain values are conceptually similar and can be grouped together. \n# For example \"MH_Benefits\" feature, I can consider combining \"I don't know\" with \"No\" \n# because they both represent a lack of awareness or access to mental health benefits\n\n# Define a function to map values to ranges\ndef map_company_size(value):\n    if value <= 100:\n        return 'Small'\n    elif 101 <= value <= 500:\n        return 'Medium'\n    else:\n        return 'Large'\n\n# Apply the mapping function to the 'Company_Size' column\ndf['Company_Size'] = df['Company_Size'].apply(map_company_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.890199Z","iopub.execute_input":"2023-11-01T11:35:39.890547Z","iopub.status.idle":"2023-11-01T11:35:39.901196Z","shell.execute_reply.started":"2023-11-01T11:35:39.890518Z","shell.execute_reply":"2023-11-01T11:35:39.900118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of values to replace with 'Uncertain'\nvalues_to_replace = [\"I am not sure\", \"I don't know\", \"Maybe\", \"Not eligible for coverage / N/A\"]\n\n# Replace the values in the entire dataframe\ndf.replace(values_to_replace, \"Uncertain\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.902628Z","iopub.execute_input":"2023-11-01T11:35:39.903219Z","iopub.status.idle":"2023-11-01T11:35:39.938055Z","shell.execute_reply.started":"2023-11-01T11:35:39.903180Z","shell.execute_reply":"2023-11-01T11:35:39.937027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Mental_Health_Medical_Leave'] = df['Mental_Health_Medical_Leave'].replace({'Very easy': 'Easy',\n    'Somewhat easy': 'Easy',\n    'Neither easy nor difficult': 'Neutral',\n    'Very difficult': 'Difficult',\n    'Somewhat difficult': 'Difficult'})","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.939271Z","iopub.execute_input":"2023-11-01T11:35:39.940221Z","iopub.status.idle":"2023-11-01T11:35:39.947238Z","shell.execute_reply.started":"2023-11-01T11:35:39.940187Z","shell.execute_reply":"2023-11-01T11:35:39.946351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Work_Position'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.948590Z","iopub.execute_input":"2023-11-01T11:35:39.949101Z","iopub.status.idle":"2023-11-01T11:35:39.964664Z","shell.execute_reply.started":"2023-11-01T11:35:39.949070Z","shell.execute_reply":"2023-11-01T11:35:39.963766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def categorize_department(role):\n    if isinstance(role, str):\n        if 'Dev' in role:\n            return 'Development'\n        elif 'Supervisor' in role or 'Executive' in role:\n            return 'Management'\n        elif 'Support' in role or 'SysAdmin' in role:\n            return 'IT'\n        elif 'Designer' in role:\n            return 'Designer'\n        else:\n            return 'Other'\n    return 'Other'\n\ndf['Work_Position'] = df['Work_Position'].apply(categorize_department)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.965855Z","iopub.execute_input":"2023-11-01T11:35:39.966355Z","iopub.status.idle":"2023-11-01T11:35:39.977217Z","shell.execute_reply.started":"2023-11-01T11:35:39.966320Z","shell.execute_reply":"2023-11-01T11:35:39.976371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style=\"whitegrid\")  # Set the style for the plot\n\n# Create a count plot\nplt.figure(figsize=(10, 6))\nsns.countplot(data=df, x=\"Current_MH_Disorder\")\n\n# Add labels and a title\nplt.xlabel(\"Current Mental Health Disorder\")\nplt.ylabel(\"Count of Respondents\")\nplt.title(\"Total Number of Respondents with Current Mental Health Disorder\")\n\n# Show the plot\nplt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:39.978507Z","iopub.execute_input":"2023-11-01T11:35:39.979001Z","iopub.status.idle":"2023-11-01T11:35:40.351560Z","shell.execute_reply.started":"2023-11-01T11:35:39.978971Z","shell.execute_reply":"2023-11-01T11:35:40.350475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current_mh_disorder_counts = df['Current_MH_Disorder'].value_counts()\n\ncolors = ['#ff9999', '#66b3ff', '#99ff99']\nfig, ax = plt.subplots(figsize=(8, 9), facecolor='none')\nax.pie(current_mh_disorder_counts, labels=current_mh_disorder_counts.index, autopct='%1.1f%%', startangle=140,\n       colors=colors, shadow=True, textprops={'fontsize': 12})\nax.set_title('Respondents with Current Mental Health Disorder', fontsize=16)\nax.axis('equal')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:40.353047Z","iopub.execute_input":"2023-11-01T11:35:40.353578Z","iopub.status.idle":"2023-11-01T11:35:40.546289Z","shell.execute_reply.started":"2023-11-01T11:35:40.353539Z","shell.execute_reply":"2023-11-01T11:35:40.545246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"has_mh_disorder = df[df['Current_MH_Disorder'] == 'Yes']  # Filter for those with a mental health disorder (2 = Yes)\nhas_mh_disorder\n\nwork_position_counts = has_mh_disorder['Work_Position'].value_counts()\nwork_position_counts\n\nplt.figure(figsize=(12, 6))\nwork_position_counts.plot(kind='bar', color='skyblue')\nplt.title('Work Positions of Respondents with Mental Health Disorder', fontsize=16)\nplt.xlabel('Work Position', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:40.547681Z","iopub.execute_input":"2023-11-01T11:35:40.548705Z","iopub.status.idle":"2023-11-01T11:35:40.851245Z","shell.execute_reply.started":"2023-11-01T11:35:40.548665Z","shell.execute_reply":"2023-11-01T11:35:40.850153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhas_mh_disorder = df[df['Current_MH_Disorder'] == 'Yes']  # Filter for those with a mental health disorder (2 = Yes)\nwork_position_counts = has_mh_disorder['Work_Position'].value_counts()\n\ncolors = ['#ff9999', '#66b3ff', '#99ff99', '#c2c2f0', '#ffb3e6']\nplt.figure(figsize=(14, 8))\nplt.pie(work_position_counts, labels=work_position_counts.index, autopct='%1.1f%%', colors=colors,\n        wedgeprops={'linewidth': 3, 'edgecolor': 'white'})\nplt.title('Work Positions of Respondents with Mental Health Disorder', fontsize=16)\nplt.axis('equal')\n\n# Add a legend\nplt.legend(work_position_counts.index, title=\"Work Position\", loc=\"lower right\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:40.852975Z","iopub.execute_input":"2023-11-01T11:35:40.854170Z","iopub.status.idle":"2023-11-01T11:35:41.094510Z","shell.execute_reply.started":"2023-11-01T11:35:40.854122Z","shell.execute_reply":"2023-11-01T11:35:41.093481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_values = df['Age']\n\nplt.figure(figsize=(10, 6))\nplt.hist(age_values, bins=10, edgecolor='k', alpha=0.7, color='skyblue')\nplt.title('Distribution of Mental Health Perceptions by Age', fontsize=16)\nplt.xlabel('Age', fontsize=12)\nplt.ylabel('Number of Respondents', fontsize=12)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:41.095785Z","iopub.execute_input":"2023-11-01T11:35:41.096112Z","iopub.status.idle":"2023-11-01T11:35:41.452515Z","shell.execute_reply.started":"2023-11-01T11:35:41.096083Z","shell.execute_reply":"2023-11-01T11:35:41.451455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter the DataFrame for respondents with 'Current_MH_disorder' equal to 'Yes'\nyes_responses = df[df['Current_MH_Disorder'] == 'Yes']\n\n\ncustom_palette = ['#377eb8', '#ff7f00', '#4daf4a', '#984ea3', '#999999', '#e41a1c', '#dede00', '#f781bf']\n\n\nplt.figure(figsize=(10, 6))\nax = sns.countplot(x='Gender', data=yes_responses, palette=custom_palette)\nplt.title('Percentage of Respondents with Current Mental Health Disorder by Gender', fontsize=16)\nplt.xlabel('Gender', fontsize=12)\nplt.ylabel('Percentage', fontsize=12)\n\n# Calculate and display percentages on top of the bars\ntotal = len(yes_responses)\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height() / total)\n    x = p.get_x() + p.get_width() / 2\n    y = p.get_height()\n    ax.annotate(percentage, (x, y), ha='center', va='bottom', fontsize=10, color='black')\n\n# Set background color and remove top and right spines\nax.set_facecolor('#f5f5f5')\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\n\n# Customize the grid lines\nax.yaxis.grid(linestyle='--', alpha=0.7)\n\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:41.455497Z","iopub.execute_input":"2023-11-01T11:35:41.455984Z","iopub.status.idle":"2023-11-01T11:35:41.891830Z","shell.execute_reply.started":"2023-11-01T11:35:41.455940Z","shell.execute_reply":"2023-11-01T11:35:41.890703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of respondents in each country for 'Country_Live' and 'Country_Work'\ncountry_live_counts = df['Country_Live'].value_counts()\ncountry_work_counts = df['Country_Work'].value_counts()\n\n# Create a GeoDataFrame with country boundaries (you may need to download a shapefile)\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\n# Merge country counts with the GeoDataFrame\nworld['Country_Live_Count'] = world['name'].map(country_live_counts)\nworld['Country_Work_Count'] = world['name'].map(country_work_counts)\n\n# Plot the geographical distribution\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 10))\n\n# Plot the distribution of 'Country_Live'\nworld.boundary.plot(ax=ax1, linewidth=0.8, color='k')\nworld.plot(column='Country_Live_Count', cmap='YlOrRd', linewidth=0.8, ax=ax1, edgecolor='0.8', legend=True)\nax1.set_title('Geographical Distribution (Country of Residence)')\nax1.axis('off')\n\n# Plot the distribution of 'Country_Work'\nworld.boundary.plot(ax=ax2, linewidth=0.8, color='k')\nworld.plot(column='Country_Work_Count', cmap='YlOrRd', linewidth=0.8, ax=ax2, edgecolor='0.8', legend=True)\nax2.set_title('Geographical Distribution (Country of Work)')\nax2.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:41.893369Z","iopub.execute_input":"2023-11-01T11:35:41.893701Z","iopub.status.idle":"2023-11-01T11:35:43.862403Z","shell.execute_reply.started":"2023-11-01T11:35:41.893672Z","shell.execute_reply":"2023-11-01T11:35:43.860633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **4. Feature Engineering**\n### Key tasks:\n* Based on the survey questions and domain knowledge, perform feature engineering to create relevant features that capture key information.\n* Encode categorical variables and text data into numerical representations.","metadata":{}},{"cell_type":"code","source":"# Get a list of numerical columns\nnumerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n\n# Get a list of categorical columns\ncategorical_columns = df.select_dtypes(exclude=['number']).columns.tolist()\n\nprint(\"Numerical Features:\")\nprint(numerical_columns)\n\nprint(\"\\nCategorical Features:\")\nprint(categorical_columns)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:43.863984Z","iopub.execute_input":"2023-11-01T11:35:43.864747Z","iopub.status.idle":"2023-11-01T11:35:43.874906Z","shell.execute_reply.started":"2023-11-01T11:35:43.864706Z","shell.execute_reply":"2023-11-01T11:35:43.873673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Determine the data types of features\nnumerical_features = df.select_dtypes(include=['number']).columns\ncategorical_features = df.select_dtypes(exclude=['number']).columns\n\n# Count the number of numerical and categorical features\nnum_numerical_features = len(numerical_features)\nnum_categorical_features = len(categorical_features)\n\n# Create a pie chart to visualize the percentage of features\nlabels = ['Numerical', 'Categorical']\nsizes = [num_numerical_features, num_categorical_features]\ncolors = ['#ff9999','#66b3ff']\nexplode = (0.1, 0)  # explode the 1st slice (i.e., 'Numerical')\n\nplt.figure(figsize=(6, 6))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\nplt.title('Percentage of Numerical and Categorical Features')\nplt.axis('equal') \n\n# Display the pie chart\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:43.882433Z","iopub.execute_input":"2023-11-01T11:35:43.882852Z","iopub.status.idle":"2023-11-01T11:35:44.101113Z","shell.execute_reply.started":"2023-11-01T11:35:43.882817Z","shell.execute_reply":"2023-11-01T11:35:44.100109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To ensure that 'Age' and 'Company_Size' is on the same scale as other features in the dataset and to\n# prevent it from dominating the modeling process due to its larger scale, I have\n# applied Min-Max Scaling to the 'Age' feature. This scaling technique transforms\n# the values of 'Age' to a consistent range between 0 and 1 while preserving the\n# relative differences in ages.\n\nscaler = MinMaxScaler()\ndf['Age'] = scaler.fit_transform(df[['Age']])","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:44.104039Z","iopub.execute_input":"2023-11-01T11:35:44.105103Z","iopub.status.idle":"2023-11-01T11:35:44.119930Z","shell.execute_reply.started":"2023-11-01T11:35:44.105037Z","shell.execute_reply":"2023-11-01T11:35:44.118548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\n# Select categorical columns\ncategorical_columns = df.select_dtypes(exclude=['number']).columns\n\n# Apply label encoding to each categorical column\nfor column in categorical_columns:\n    df[column] = label_encoder.fit_transform(df[column])","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:44.122151Z","iopub.execute_input":"2023-11-01T11:35:44.123774Z","iopub.status.idle":"2023-11-01T11:35:44.165771Z","shell.execute_reply.started":"2023-11-01T11:35:44.123710Z","shell.execute_reply":"2023-11-01T11:35:44.164663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:44.167124Z","iopub.execute_input":"2023-11-01T11:35:44.167495Z","iopub.status.idle":"2023-11-01T11:35:44.195466Z","shell.execute_reply.started":"2023-11-01T11:35:44.167463Z","shell.execute_reply":"2023-11-01T11:35:44.193704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.25\n\n# Initialize the VarianceThreshold selector\nselector = VarianceThreshold(threshold)\n\nselected_features = selector.fit_transform(df)\n\n# Get the mask of selected features (True for selected, False for discarded)\nfeature_mask = selector.get_support()\n\n# Create a new DataFrame with selected features\ndf = df.loc[:, feature_mask]","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:44.197133Z","iopub.execute_input":"2023-11-01T11:35:44.197517Z","iopub.status.idle":"2023-11-01T11:35:44.212827Z","shell.execute_reply.started":"2023-11-01T11:35:44.197485Z","shell.execute_reply":"2023-11-01T11:35:44.211730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Correlation Analysis\n\ncorrelation_matrix = df.corr()\n\nplt.figure(figsize=(26, 22))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:44.214426Z","iopub.execute_input":"2023-11-01T11:35:44.214902Z","iopub.status.idle":"2023-11-01T11:35:49.034607Z","shell.execute_reply.started":"2023-11-01T11:35:44.214860Z","shell.execute_reply":"2023-11-01T11:35:49.033369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix = df.corr()\n\n# Create a mask for highly correlated features\n# The mask will be True for correlated pairs, and we'll keep the first feature\ncorrelation_mask = (correlation_matrix.abs() > 0.7) & (correlation_matrix != 1)\n\n# Identify columns (features) to drop\ncolumns_to_drop = set()\nfor feature in correlation_mask.columns:\n    correlated_features = correlation_mask.index[correlation_mask[feature]]\n    if len(correlated_features) > 0:\n        columns_to_drop.add(feature)\n\n# Remove highly correlated columns from the DataFrame\ndf = df.drop(columns=columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:49.036037Z","iopub.execute_input":"2023-11-01T11:35:49.036775Z","iopub.status.idle":"2023-11-01T11:35:49.055928Z","shell.execute_reply.started":"2023-11-01T11:35:49.036742Z","shell.execute_reply":"2023-11-01T11:35:49.054876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:49.057091Z","iopub.execute_input":"2023-11-01T11:35:49.057487Z","iopub.status.idle":"2023-11-01T11:35:49.076937Z","shell.execute_reply.started":"2023-11-01T11:35:49.057459Z","shell.execute_reply":"2023-11-01T11:35:49.075784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **5: Dimensional Reduction and Clustering** \n### Key tasks:\n* Perform dimensionality reduction using the Principal Component Analysis (PCA) technique to reduce the dimensionality of the dataset.\n* Perfrom K-Means Clustering","metadata":{"execution":{"iopub.status.busy":"2023-10-07T16:28:44.038498Z","iopub.execute_input":"2023-10-07T16:28:44.038895Z","iopub.status.idle":"2023-10-07T16:28:44.048183Z","shell.execute_reply.started":"2023-10-07T16:28:44.038865Z","shell.execute_reply":"2023-10-07T16:28:44.046583Z"}}},{"cell_type":"code","source":"pca = PCA()\npca.fit(df)\nexplained_variance = pca.explained_variance_ratio_\ncumulative_variance = np.cumsum(explained_variance)\n\n# Plot the cumulative explained variance\nplt.plot(cumulative_variance)\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:49.078455Z","iopub.execute_input":"2023-11-01T11:35:49.078862Z","iopub.status.idle":"2023-11-01T11:35:49.498479Z","shell.execute_reply.started":"2023-11-01T11:35:49.078826Z","shell.execute_reply":"2023-11-01T11:35:49.497565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(1, len(explained_variance) + 1), explained_variance)\nplt.xlabel('Number of Components')\nplt.ylabel('Explained Variance')","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:49.499822Z","iopub.execute_input":"2023-11-01T11:35:49.500156Z","iopub.status.idle":"2023-11-01T11:35:49.858950Z","shell.execute_reply.started":"2023-11-01T11:35:49.500128Z","shell.execute_reply":"2023-11-01T11:35:49.857864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize the numerical features (important for PCA)\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(df)\n\npca = PCA(n_components=2)\n\n# Fit PCA to the scaled data\nprincipal_components = pca.fit_transform(df)\n\n# Create a new DataFrame with the principal components\nprincipal_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:49.860717Z","iopub.execute_input":"2023-11-01T11:35:49.861338Z","iopub.status.idle":"2023-11-01T11:35:49.899104Z","shell.execute_reply.started":"2023-11-01T11:35:49.861279Z","shell.execute_reply":"2023-11-01T11:35:49.897732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"principal_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:49.900863Z","iopub.execute_input":"2023-11-01T11:35:49.901259Z","iopub.status.idle":"2023-11-01T11:35:49.917993Z","shell.execute_reply.started":"2023-11-01T11:35:49.901222Z","shell.execute_reply":"2023-11-01T11:35:49.916779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract PC1 and PC2 values from principal_df\nPC1 = principal_df['PC1']\nPC2 = principal_df['PC2']\n\n# Create a scatter plot\nplt.figure(figsize=(10, 6))\nplt.scatter(PC1, PC2, alpha=0.5)  # alpha controls point transparency\n\nplt.title('PCA: PC1 vs. PC2', fontsize=16)\nplt.xlabel('PC1', fontsize=12)\nplt.ylabel('PC2', fontsize=12)\n\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:49.920034Z","iopub.execute_input":"2023-11-01T11:35:49.920479Z","iopub.status.idle":"2023-11-01T11:35:50.357461Z","shell.execute_reply.started":"2023-11-01T11:35:49.920441Z","shell.execute_reply":"2023-11-01T11:35:50.356364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wcss = []  # Within-cluster sum of squares\n\n# Iterate through a range of k values\nfor k in range(1, 11):\n    kmeans = KMeans(n_clusters=k,n_init=10, random_state=42)\n    kmeans.fit(df)\n    wcss.append(kmeans.inertia_)  # Sum of squared distances to nearest cluster center\n    \n# Rest of your code to plot the elbow curve\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, 11), wcss, marker='o', linestyle='-', color='b')\nplt.title('Elbow Method for Optimal k')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('Within-Cluster Sum of Squares (WCSS)')\nplt.grid(True)\n\n# Add an arrow pointing at the fourth cluster on the right-hand side\narrow_properties = dict(\n    facecolor='red', edgecolor='red',\n    arrowstyle='->, head_width=0.5', connectionstyle='arc3, rad=0.3'\n)\nplt.annotate('Optimal k (4)', xy=(4, wcss[3]), xytext=(7, wcss[3] + 10000),\n             arrowprops=arrow_properties, fontsize=12, color='red')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:35:50.358999Z","iopub.execute_input":"2023-11-01T11:35:50.359915Z","iopub.status.idle":"2023-11-01T11:36:02.058997Z","shell.execute_reply.started":"2023-11-01T11:35:50.359876Z","shell.execute_reply":"2023-11-01T11:36:02.057903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 4\n\nkmeans = KMeans(n_clusters=k,n_init=10, random_state=42)\nkmeans.fit(df)\n\n# Get cluster labels for each data point\nclusters = kmeans.labels_\n\nprincipal_df['Cluster'] = clusters","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:36:02.060471Z","iopub.execute_input":"2023-11-01T11:36:02.060800Z","iopub.status.idle":"2023-11-01T11:36:03.777006Z","shell.execute_reply.started":"2023-11-01T11:36:02.060771Z","shell.execute_reply":"2023-11-01T11:36:03.776057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **6. Results and Visualizations**\n* Cluster Characteristics.\n* Evaluate the quality of clusters using the silhouette score.\n* Cluster Visualization.\n* Key Findings","metadata":{}},{"cell_type":"code","source":"\n# Create a scatter plot of the PCA-transformed data with color-coded clusters\nplt.figure(figsize=(10, 8))\nfor cluster in range(k):\n    data = principal_df[principal_df['Cluster'] == cluster]\n    plt.scatter(data['PC1'], data['PC2'], label=f'Cluster {cluster}')\n\nplt.title('K-Means Clustering Results (PCA)')\nplt.xlabel('Principal Component 1 (PC1)')\nplt.ylabel('Principal Component 2 (PC2)')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:36:03.778246Z","iopub.execute_input":"2023-11-01T11:36:03.781853Z","iopub.status.idle":"2023-11-01T11:36:04.291758Z","shell.execute_reply.started":"2023-11-01T11:36:03.781811Z","shell.execute_reply":"2023-11-01T11:36:04.287853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the silhouette score\nsilhouette_avg = silhouette_score(principal_df[['PC1', 'PC2', 'Cluster']], principal_df['Cluster'])\n\nprint(f\"Silhouette Score: {silhouette_avg}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:36:04.292780Z","iopub.execute_input":"2023-11-01T11:36:04.293377Z","iopub.status.idle":"2023-11-01T11:36:04.358967Z","shell.execute_reply.started":"2023-11-01T11:36:04.293344Z","shell.execute_reply":"2023-11-01T11:36:04.357953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Analyze the clusters and their characteristics\ndf['Cluster'] = clusters\ncluster_groups = df.groupby('Cluster')\n\nfor cluster, group in cluster_groups:\n    print(f\"Cluster {cluster}:\")\n    print(group.describe().T)\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:36:04.363776Z","iopub.execute_input":"2023-11-01T11:36:04.364727Z","iopub.status.idle":"2023-11-01T11:36:04.731060Z","shell.execute_reply.started":"2023-11-01T11:36:04.364685Z","shell.execute_reply":"2023-11-01T11:36:04.728645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Group the data by clusters\ncluster_groups = df.groupby('Cluster')\n\n# Create a new directory to save cluster-specific visualizations\nimport os\nif not os.path.exists('cluster_visualizations'):\n    os.makedirs('cluster_visualizations')\n\n# Iterate through clusters and create histograms for numerical features\nfor cluster, group in cluster_groups:\n    print(f\"Cluster {cluster}:\")\n\n    # Select numerical columns to visualize\n    numeric_features = group.select_dtypes(include=['int64', 'float64'])\n\n    # Determine the number of rows and columns for subplots\n    n_rows = (len(numeric_features.columns) + 2) // 3  # 3 subplots per row\n    n_cols = min(len(numeric_features.columns), 3)  # Up to 3 subplots in a row\n\n    # Set up subplots\n    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(16, 28))\n    fig.suptitle(f\"Cluster {cluster} - Histograms of Numerical Features\", fontsize=16)\n    axes = axes.ravel()\n\n    for i, col in enumerate(numeric_features.columns):\n        axes[i].hist(group[col], bins=20, color='skyblue', edgecolor='black')\n        axes[i].set_title(col)\n        axes[i].set_xlabel(col)\n        axes[i].set_ylabel(\"Frequency\")\n\n    # Remove any empty subplots\n    for i in range(len(numeric_features.columns), n_rows * n_cols):\n        fig.delaxes(axes[i])\n\n    plt.tight_layout()\n    plt.subplots_adjust(top=0.9)\n\n    # Save the visualization to a file\n    plt.savefig(f'cluster_visualizations/cluster_{cluster}_histograms.png')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:36:04.732412Z","iopub.execute_input":"2023-11-01T11:36:04.732705Z","iopub.status.idle":"2023-11-01T11:37:18.831474Z","shell.execute_reply.started":"2023-11-01T11:36:04.732680Z","shell.execute_reply":"2023-11-01T11:37:18.830425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"variables_of_interest = ['Work_Position', 'Work_Remotely']\n\n\ncluster_width = 0.2 \n\nfor variable in variables_of_interest:\n    plt.figure(figsize=(6, 6))\n    x_positions = None \n    \n    for cluster in range(k): \n        cluster_data = df[df['Cluster'] == cluster]\n        variable_counts = cluster_data[variable].value_counts().sort_index()\n        \n        if x_positions is None:\n            x_positions = range(len(variable_counts))\n        \n\n        plt.bar([x + cluster * cluster_width for x in x_positions], variable_counts.values, width=cluster_width, label=f'Cluster {cluster}')\n        \n    plt.title(f'Bar Chart of {variable} by Cluster')\n    plt.xlabel(variable)\n    plt.ylabel('Count')\n    plt.legend()\n    plt.xticks([x + ((k - 1) * cluster_width) / 2 for x in x_positions], variable_counts.index)\n    plt.grid(True)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T11:37:18.832930Z","iopub.execute_input":"2023-11-01T11:37:18.833748Z","iopub.status.idle":"2023-11-01T11:37:19.766464Z","shell.execute_reply.started":"2023-11-01T11:37:18.833698Z","shell.execute_reply":"2023-11-01T11:37:19.765288Z"},"trusted":true},"execution_count":null,"outputs":[]}]}